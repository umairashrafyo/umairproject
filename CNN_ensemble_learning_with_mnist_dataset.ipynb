{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": " CNN ensemble learning with mnist dataset.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1VcqamyTD8Hy4CKvBmUT0qOFFzeOcpy9y",
      "authorship_tag": "ABX9TyPprWNEmFLXb40TG9SYN2BC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/umairashrafyo/umairproject/blob/main/CNN_ensemble_learning_with_mnist_dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T2lQrZ5E82w2"
      },
      "source": [
        "#First, we need to import the required libraries. \n",
        "import tensorflow.keras\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix, mean_squared_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "import itertools\n",
        "import math\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\n",
        "from keras.utils.np_utils import to_categorical # convert to one-hot-encoding\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.optimizers import Adam, RMSprop, Adagrad"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QaOIR38_9Jqv"
      },
      "source": [
        "#After importing the required libraries, we will read the MNIST handwritten data set that is provided publicly in Google Colab as sample data.\n",
        "#Reading the data\n",
        "train = pd.read_csv(\"/content/drive/MyDrive/mnist dataset/train.csv\")\n",
        "test = pd.read_csv(\"/content/drive/MyDrive/mnist dataset/test.csv\")"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "id": "OdGxoO-19p85",
        "outputId": "b257f0c2-bc03-4e07-b32d-3f84ead0f9be"
      },
      "source": [
        "#Now, we need to specify the training and test sets. It will be done using the below lines of codes. First, we will check the header and then we will identify the required columns\n",
        "#Training data head\n",
        "train.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>pixel0</th>\n",
              "      <th>pixel1</th>\n",
              "      <th>pixel2</th>\n",
              "      <th>pixel3</th>\n",
              "      <th>pixel4</th>\n",
              "      <th>pixel5</th>\n",
              "      <th>pixel6</th>\n",
              "      <th>pixel7</th>\n",
              "      <th>pixel8</th>\n",
              "      <th>pixel9</th>\n",
              "      <th>pixel10</th>\n",
              "      <th>pixel11</th>\n",
              "      <th>pixel12</th>\n",
              "      <th>pixel13</th>\n",
              "      <th>pixel14</th>\n",
              "      <th>pixel15</th>\n",
              "      <th>pixel16</th>\n",
              "      <th>pixel17</th>\n",
              "      <th>pixel18</th>\n",
              "      <th>pixel19</th>\n",
              "      <th>pixel20</th>\n",
              "      <th>pixel21</th>\n",
              "      <th>pixel22</th>\n",
              "      <th>pixel23</th>\n",
              "      <th>pixel24</th>\n",
              "      <th>pixel25</th>\n",
              "      <th>pixel26</th>\n",
              "      <th>pixel27</th>\n",
              "      <th>pixel28</th>\n",
              "      <th>pixel29</th>\n",
              "      <th>pixel30</th>\n",
              "      <th>pixel31</th>\n",
              "      <th>pixel32</th>\n",
              "      <th>pixel33</th>\n",
              "      <th>pixel34</th>\n",
              "      <th>pixel35</th>\n",
              "      <th>pixel36</th>\n",
              "      <th>pixel37</th>\n",
              "      <th>pixel38</th>\n",
              "      <th>...</th>\n",
              "      <th>pixel744</th>\n",
              "      <th>pixel745</th>\n",
              "      <th>pixel746</th>\n",
              "      <th>pixel747</th>\n",
              "      <th>pixel748</th>\n",
              "      <th>pixel749</th>\n",
              "      <th>pixel750</th>\n",
              "      <th>pixel751</th>\n",
              "      <th>pixel752</th>\n",
              "      <th>pixel753</th>\n",
              "      <th>pixel754</th>\n",
              "      <th>pixel755</th>\n",
              "      <th>pixel756</th>\n",
              "      <th>pixel757</th>\n",
              "      <th>pixel758</th>\n",
              "      <th>pixel759</th>\n",
              "      <th>pixel760</th>\n",
              "      <th>pixel761</th>\n",
              "      <th>pixel762</th>\n",
              "      <th>pixel763</th>\n",
              "      <th>pixel764</th>\n",
              "      <th>pixel765</th>\n",
              "      <th>pixel766</th>\n",
              "      <th>pixel767</th>\n",
              "      <th>pixel768</th>\n",
              "      <th>pixel769</th>\n",
              "      <th>pixel770</th>\n",
              "      <th>pixel771</th>\n",
              "      <th>pixel772</th>\n",
              "      <th>pixel773</th>\n",
              "      <th>pixel774</th>\n",
              "      <th>pixel775</th>\n",
              "      <th>pixel776</th>\n",
              "      <th>pixel777</th>\n",
              "      <th>pixel778</th>\n",
              "      <th>pixel779</th>\n",
              "      <th>pixel780</th>\n",
              "      <th>pixel781</th>\n",
              "      <th>pixel782</th>\n",
              "      <th>pixel783</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 785 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   label  pixel0  pixel1  pixel2  ...  pixel780  pixel781  pixel782  pixel783\n",
              "0      1       0       0       0  ...         0         0         0         0\n",
              "1      0       0       0       0  ...         0         0         0         0\n",
              "2      1       0       0       0  ...         0         0         0         0\n",
              "3      4       0       0       0  ...         0         0         0         0\n",
              "4      0       0       0       0  ...         0         0         0         0\n",
              "\n",
              "[5 rows x 785 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HRZglnZO9uaq",
        "outputId": "20d32549-8800-4384-9ca7-ba24a7287815"
      },
      "source": [
        "#Specifying train and test data\n",
        "train_X = train.iloc[:,1:]\n",
        "train_y = train.iloc[:,0]\n",
        "test = test.iloc[:,1:]\n",
        "\n",
        "#Shape of the specified data\n",
        "print(train_X.shape)\n",
        "print(train_y.shape)\n",
        "print(test.shape)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(19999, 784)\n",
            "(19999,)\n",
            "(9999, 784)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "82S6BIR_9wrL"
      },
      "source": [
        "#Now, we will normalize the training and test data\n",
        "#Normalize the data\n",
        "train_X = train_X / 255.0\n",
        "test = test / 255.0"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5xfa0BdJ9zCU"
      },
      "source": [
        "#Reshape image in 3 dimensions (with 1 channel)\n",
        "train_X = train_X.values.reshape(-1,28,28,1)\n",
        "test = test.values.reshape(-1,28,28,1)\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b2xOSDa491Qm"
      },
      "source": [
        "#Encode labels to one hot vectors\n",
        "train_y = to_categorical(train_y, num_classes = 10)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "n8SpemK693kn",
        "outputId": "1ecb25f3-08e6-4ee2-cf1b-0d2e7ee8aa10"
      },
      "source": [
        "#Sample image\n",
        "plt.imshow(train_X[0][:,:,0])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f800c348fd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dWpLD9RY96iX",
        "outputId": "97c2bbc7-d7af-4ca7-e74e-147a3d041c1b"
      },
      "source": [
        "#Ensemble Of Convolutional Neural Networks\n",
        "# Define 10 CNN models\n",
        "from keras.optimizers import RMSprop, Adam\n",
        "from keras.layers import DepthwiseConv2D, Reshape, Activation\n",
        "\n",
        "nets = 10\n",
        "model = [0] *nets\n",
        "\n",
        "for j in range(nets):\n",
        "    model[j] = Sequential()\n",
        "    #First Layer\n",
        "    model[j].add(Conv2D(32, kernel_size = 3, activation='relu', input_shape = (28, 28, 1)))\n",
        "    model[j].add(BatchNormalization())\n",
        "    model[j].add(Conv2D(32, kernel_size = 3, activation='relu'))\n",
        "    model[j].add(BatchNormalization())\n",
        "    model[j].add(Conv2D(32, kernel_size = 5, strides=2, padding='same', activation='relu'))\n",
        "    model[j].add(BatchNormalization())\n",
        "    model[j].add(Dropout(0.4))\n",
        "\n",
        "    #Second Layer\n",
        "    model[j].add(Conv2D(64, kernel_size = 3, activation='relu'))\n",
        "    model[j].add(BatchNormalization())\n",
        "    model[j].add(Conv2D(64, kernel_size = 3, activation='relu'))\n",
        "    model[j].add(BatchNormalization())\n",
        "    model[j].add(Conv2D(64, kernel_size = 5, strides=2, padding='same', activation='relu'))\n",
        "    model[j].add(BatchNormalization())\n",
        "    model[j].add(Dropout(0.4))\n",
        "\n",
        "    #Third layer\n",
        "    model[j].add(Conv2D(128, kernel_size = 4, activation='relu'))\n",
        "    model[j].add(BatchNormalization())\n",
        "    model[j].add(Flatten())\n",
        "    model[j].add(Dropout(0.4))\n",
        "\n",
        "    #Output layer\n",
        "    model[j].add(Dense(10, activation='softmax'))\n",
        "\n",
        "    # Compile each model\n",
        "    model[j].compile(optimizer='adam', loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "    \n",
        "print('All Models Defined')\n"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "All Models Defined\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yyfv1a0R-Hux"
      },
      "source": [
        "#We will use the learning rate annealer in this experiment. The learning rate annealer decreases the learning rate after a certain number of epochs if the error rate does not change. Here, through this technique, we will monitor the validation accuracy and if it seems to be a plateau in 3 epochs, it will reduce the learning rate.\n",
        "#LR Reduction Callback\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "learning_rate_reduction=ReduceLROnPlateau(monitor='val_accuracy', patience=3, verbose=0, factor=0.5, min_lr=0.00001)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gYb1Py1e-KoU",
        "outputId": "6c45ad6d-0c98-4416-b9ca-bbb9c432dffa"
      },
      "source": [
        "#In the next step, we will train the models that we have defined above.\n",
        "# train for 20 epochs\n",
        "# train for 20 epochs\n",
        "history = [0] * nets\n",
        "epochs = 20\n",
        "\n",
        "datagen = ImageDataGenerator(rotation_range=13, zoom_range=0.11, width_shift_range=0.1, height_shift_range=0.1)\n",
        "\n",
        "datagen.fit(train_X)\n",
        "\n",
        "for j in range(nets):\n",
        "    print(f'Individual Net : {j+1}')   \n",
        "    X_train2, X_val2, Y_train2, Y_val2 = train_test_split(train_X, train_y, test_size = 0.1)\n",
        "    history[j] = model[j].fit(datagen.flow(X_train2,Y_train2, batch_size=64), epochs = epochs, steps_per_epoch = X_train2.shape[0]//64, validation_data = (X_val2,Y_val2), callbacks=[learning_rate_reduction], verbose=1)\n",
        "\n",
        "    print(\"CNN Model {0:d}: Epochs={1:d}, Training accuracy={2:.5f}, Validation accuracy={3:.5f}\".format(j+1,epochs,max(history[j].history['accuracy']),max(history[j].history['val_accuracy']) ))\n"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Individual Net : 1\n",
            "Epoch 1/20\n",
            "281/281 [==============================] - 80s 279ms/step - loss: 1.4529 - accuracy: 0.5668 - val_loss: 7.0598 - val_accuracy: 0.1025\n",
            "Epoch 2/20\n",
            "281/281 [==============================] - 78s 278ms/step - loss: 0.2601 - accuracy: 0.9183 - val_loss: 0.3419 - val_accuracy: 0.8820\n",
            "Epoch 3/20\n",
            "281/281 [==============================] - 79s 280ms/step - loss: 0.1526 - accuracy: 0.9535 - val_loss: 0.0444 - val_accuracy: 0.9880\n",
            "Epoch 4/20\n",
            "281/281 [==============================] - 79s 281ms/step - loss: 0.1354 - accuracy: 0.9562 - val_loss: 0.0443 - val_accuracy: 0.9865\n",
            "Epoch 5/20\n",
            "281/281 [==============================] - 78s 279ms/step - loss: 0.1121 - accuracy: 0.9655 - val_loss: 0.0653 - val_accuracy: 0.9840\n",
            "Epoch 6/20\n",
            "281/281 [==============================] - 78s 279ms/step - loss: 0.1003 - accuracy: 0.9683 - val_loss: 0.0313 - val_accuracy: 0.9910\n",
            "Epoch 7/20\n",
            "281/281 [==============================] - 78s 278ms/step - loss: 0.0935 - accuracy: 0.9746 - val_loss: 0.0378 - val_accuracy: 0.9905\n",
            "Epoch 8/20\n",
            "281/281 [==============================] - 78s 277ms/step - loss: 0.0829 - accuracy: 0.9743 - val_loss: 0.0531 - val_accuracy: 0.9845\n",
            "Epoch 9/20\n",
            "281/281 [==============================] - 78s 276ms/step - loss: 0.0806 - accuracy: 0.9750 - val_loss: 0.0404 - val_accuracy: 0.9900\n",
            "Epoch 10/20\n",
            "281/281 [==============================] - 78s 276ms/step - loss: 0.0737 - accuracy: 0.9771 - val_loss: 0.0244 - val_accuracy: 0.9930\n",
            "Epoch 11/20\n",
            "281/281 [==============================] - 78s 277ms/step - loss: 0.0599 - accuracy: 0.9816 - val_loss: 0.0308 - val_accuracy: 0.9895\n",
            "Epoch 12/20\n",
            "281/281 [==============================] - 77s 274ms/step - loss: 0.0556 - accuracy: 0.9837 - val_loss: 0.0293 - val_accuracy: 0.9920\n",
            "Epoch 13/20\n",
            "281/281 [==============================] - 77s 275ms/step - loss: 0.0551 - accuracy: 0.9844 - val_loss: 0.0215 - val_accuracy: 0.9920\n",
            "Epoch 14/20\n",
            "281/281 [==============================] - 77s 275ms/step - loss: 0.0449 - accuracy: 0.9870 - val_loss: 0.0239 - val_accuracy: 0.9935\n",
            "Epoch 15/20\n",
            "281/281 [==============================] - 78s 277ms/step - loss: 0.0414 - accuracy: 0.9874 - val_loss: 0.0208 - val_accuracy: 0.9935\n",
            "Epoch 16/20\n",
            "281/281 [==============================] - 78s 276ms/step - loss: 0.0412 - accuracy: 0.9878 - val_loss: 0.0230 - val_accuracy: 0.9915\n",
            "Epoch 17/20\n",
            "281/281 [==============================] - 77s 274ms/step - loss: 0.0459 - accuracy: 0.9857 - val_loss: 0.0224 - val_accuracy: 0.9925\n",
            "Epoch 18/20\n",
            "281/281 [==============================] - 78s 276ms/step - loss: 0.0386 - accuracy: 0.9866 - val_loss: 0.0187 - val_accuracy: 0.9925\n",
            "Epoch 19/20\n",
            "281/281 [==============================] - 77s 275ms/step - loss: 0.0353 - accuracy: 0.9897 - val_loss: 0.0219 - val_accuracy: 0.9945\n",
            "Epoch 20/20\n",
            "281/281 [==============================] - 78s 276ms/step - loss: 0.0320 - accuracy: 0.9893 - val_loss: 0.0267 - val_accuracy: 0.9925\n",
            "CNN Model 1: Epochs=20, Training accuracy=0.98968, Validation accuracy=0.99450\n",
            "Individual Net : 2\n",
            "Epoch 1/20\n",
            "281/281 [==============================] - 79s 276ms/step - loss: 1.4379 - accuracy: 0.5727 - val_loss: 6.3697 - val_accuracy: 0.1080\n",
            "Epoch 2/20\n",
            "281/281 [==============================] - 78s 277ms/step - loss: 0.2562 - accuracy: 0.9206 - val_loss: 0.2527 - val_accuracy: 0.9200\n",
            "Epoch 3/20\n",
            "281/281 [==============================] - 78s 277ms/step - loss: 0.1790 - accuracy: 0.9424 - val_loss: 0.0587 - val_accuracy: 0.9815\n",
            "Epoch 4/20\n",
            "281/281 [==============================] - 77s 274ms/step - loss: 0.1486 - accuracy: 0.9553 - val_loss: 0.0702 - val_accuracy: 0.9825\n",
            "Epoch 5/20\n",
            "281/281 [==============================] - 77s 273ms/step - loss: 0.1267 - accuracy: 0.9628 - val_loss: 0.0988 - val_accuracy: 0.9760\n",
            "Epoch 6/20\n",
            "281/281 [==============================] - 77s 273ms/step - loss: 0.1168 - accuracy: 0.9615 - val_loss: 0.0555 - val_accuracy: 0.9815\n",
            "Epoch 7/20\n",
            "281/281 [==============================] - 77s 274ms/step - loss: 0.0962 - accuracy: 0.9701 - val_loss: 0.0488 - val_accuracy: 0.9840\n",
            "Epoch 8/20\n",
            "281/281 [==============================] - 77s 274ms/step - loss: 0.0923 - accuracy: 0.9724 - val_loss: 0.0581 - val_accuracy: 0.9830\n",
            "Epoch 9/20\n",
            "281/281 [==============================] - 77s 272ms/step - loss: 0.0819 - accuracy: 0.9763 - val_loss: 0.0355 - val_accuracy: 0.9855\n",
            "Epoch 10/20\n",
            "281/281 [==============================] - 77s 273ms/step - loss: 0.0793 - accuracy: 0.9771 - val_loss: 0.0341 - val_accuracy: 0.9885\n",
            "Epoch 11/20\n",
            "281/281 [==============================] - 77s 274ms/step - loss: 0.0850 - accuracy: 0.9740 - val_loss: 0.0389 - val_accuracy: 0.9875\n",
            "Epoch 12/20\n",
            "281/281 [==============================] - 77s 273ms/step - loss: 0.0793 - accuracy: 0.9729 - val_loss: 0.0289 - val_accuracy: 0.9910\n",
            "Epoch 13/20\n",
            "281/281 [==============================] - 77s 274ms/step - loss: 0.0656 - accuracy: 0.9810 - val_loss: 0.0364 - val_accuracy: 0.9875\n",
            "Epoch 14/20\n",
            "281/281 [==============================] - 77s 274ms/step - loss: 0.0670 - accuracy: 0.9791 - val_loss: 0.0784 - val_accuracy: 0.9785\n",
            "Epoch 15/20\n",
            "281/281 [==============================] - 77s 274ms/step - loss: 0.0661 - accuracy: 0.9803 - val_loss: 0.0305 - val_accuracy: 0.9905\n",
            "Epoch 16/20\n",
            "281/281 [==============================] - 76s 272ms/step - loss: 0.0548 - accuracy: 0.9833 - val_loss: 0.0269 - val_accuracy: 0.9920\n",
            "Epoch 17/20\n",
            "281/281 [==============================] - 76s 272ms/step - loss: 0.0504 - accuracy: 0.9843 - val_loss: 0.0270 - val_accuracy: 0.9910\n",
            "Epoch 18/20\n",
            "281/281 [==============================] - 77s 273ms/step - loss: 0.0432 - accuracy: 0.9859 - val_loss: 0.0220 - val_accuracy: 0.9935\n",
            "Epoch 19/20\n",
            "281/281 [==============================] - 77s 275ms/step - loss: 0.0430 - accuracy: 0.9871 - val_loss: 0.0278 - val_accuracy: 0.9925\n",
            "Epoch 20/20\n",
            "281/281 [==============================] - 77s 273ms/step - loss: 0.0459 - accuracy: 0.9858 - val_loss: 0.0226 - val_accuracy: 0.9940\n",
            "CNN Model 2: Epochs=20, Training accuracy=0.98723, Validation accuracy=0.99400\n",
            "Individual Net : 3\n",
            "Epoch 1/20\n",
            "281/281 [==============================] - 78s 274ms/step - loss: 1.3768 - accuracy: 0.5957 - val_loss: 3.2986 - val_accuracy: 0.3585\n",
            "Epoch 2/20\n",
            "281/281 [==============================] - 77s 274ms/step - loss: 0.2248 - accuracy: 0.9323 - val_loss: 0.2539 - val_accuracy: 0.9210\n",
            "Epoch 3/20\n",
            "281/281 [==============================] - 77s 276ms/step - loss: 0.1646 - accuracy: 0.9520 - val_loss: 0.0474 - val_accuracy: 0.9880\n",
            "Epoch 4/20\n",
            "281/281 [==============================] - 77s 274ms/step - loss: 0.1254 - accuracy: 0.9636 - val_loss: 0.0423 - val_accuracy: 0.9860\n",
            "Epoch 5/20\n",
            "281/281 [==============================] - 77s 273ms/step - loss: 0.1135 - accuracy: 0.9664 - val_loss: 0.0413 - val_accuracy: 0.9890\n",
            "Epoch 6/20\n",
            "281/281 [==============================] - 77s 275ms/step - loss: 0.0925 - accuracy: 0.9723 - val_loss: 0.0368 - val_accuracy: 0.9885\n",
            "Epoch 7/20\n",
            "281/281 [==============================] - 78s 279ms/step - loss: 0.0948 - accuracy: 0.9717 - val_loss: 0.0392 - val_accuracy: 0.9910\n",
            "Epoch 8/20\n",
            "281/281 [==============================] - 78s 278ms/step - loss: 0.0887 - accuracy: 0.9729 - val_loss: 0.0459 - val_accuracy: 0.9840\n",
            "Epoch 9/20\n",
            "281/281 [==============================] - 78s 276ms/step - loss: 0.0789 - accuracy: 0.9753 - val_loss: 0.0373 - val_accuracy: 0.9895\n",
            "Epoch 10/20\n",
            "281/281 [==============================] - 77s 274ms/step - loss: 0.0776 - accuracy: 0.9755 - val_loss: 0.0332 - val_accuracy: 0.9885\n",
            "Epoch 11/20\n",
            "281/281 [==============================] - 77s 275ms/step - loss: 0.0580 - accuracy: 0.9822 - val_loss: 0.0243 - val_accuracy: 0.9925\n",
            "Epoch 12/20\n",
            "281/281 [==============================] - 77s 274ms/step - loss: 0.0429 - accuracy: 0.9871 - val_loss: 0.0236 - val_accuracy: 0.9935\n",
            "Epoch 13/20\n",
            "281/281 [==============================] - 77s 274ms/step - loss: 0.0450 - accuracy: 0.9854 - val_loss: 0.0251 - val_accuracy: 0.9930\n",
            "Epoch 14/20\n",
            "281/281 [==============================] - 78s 277ms/step - loss: 0.0501 - accuracy: 0.9840 - val_loss: 0.0249 - val_accuracy: 0.9925\n",
            "Epoch 15/20\n",
            "281/281 [==============================] - 77s 275ms/step - loss: 0.0475 - accuracy: 0.9864 - val_loss: 0.0261 - val_accuracy: 0.9935\n",
            "Epoch 16/20\n",
            "281/281 [==============================] - 77s 274ms/step - loss: 0.0421 - accuracy: 0.9867 - val_loss: 0.0174 - val_accuracy: 0.9950\n",
            "Epoch 17/20\n",
            "281/281 [==============================] - 77s 273ms/step - loss: 0.0391 - accuracy: 0.9889 - val_loss: 0.0202 - val_accuracy: 0.9940\n",
            "Epoch 18/20\n",
            "281/281 [==============================] - 77s 273ms/step - loss: 0.0361 - accuracy: 0.9888 - val_loss: 0.0228 - val_accuracy: 0.9925\n",
            "Epoch 19/20\n",
            "281/281 [==============================] - 77s 273ms/step - loss: 0.0395 - accuracy: 0.9882 - val_loss: 0.0189 - val_accuracy: 0.9930\n",
            "Epoch 20/20\n",
            "281/281 [==============================] - 77s 274ms/step - loss: 0.0340 - accuracy: 0.9891 - val_loss: 0.0183 - val_accuracy: 0.9935\n",
            "CNN Model 3: Epochs=20, Training accuracy=0.98913, Validation accuracy=0.99500\n",
            "Individual Net : 4\n",
            "Epoch 1/20\n",
            "281/281 [==============================] - 78s 275ms/step - loss: 1.4567 - accuracy: 0.5632 - val_loss: 2.5575 - val_accuracy: 0.1740\n",
            "Epoch 2/20\n",
            "281/281 [==============================] - 77s 273ms/step - loss: 0.2416 - accuracy: 0.9267 - val_loss: 0.0983 - val_accuracy: 0.9710\n",
            "Epoch 3/20\n",
            "281/281 [==============================] - 77s 274ms/step - loss: 0.1765 - accuracy: 0.9445 - val_loss: 0.0637 - val_accuracy: 0.9795\n",
            "Epoch 4/20\n",
            "281/281 [==============================] - 77s 273ms/step - loss: 0.1367 - accuracy: 0.9595 - val_loss: 0.0569 - val_accuracy: 0.9835\n",
            "Epoch 5/20\n",
            "281/281 [==============================] - 77s 275ms/step - loss: 0.0967 - accuracy: 0.9699 - val_loss: 0.0527 - val_accuracy: 0.9830\n",
            "Epoch 6/20\n",
            "281/281 [==============================] - 77s 274ms/step - loss: 0.1060 - accuracy: 0.9655 - val_loss: 0.0618 - val_accuracy: 0.9795\n",
            "Epoch 7/20\n",
            "281/281 [==============================] - 78s 277ms/step - loss: 0.1033 - accuracy: 0.9679 - val_loss: 0.0483 - val_accuracy: 0.9845\n",
            "Epoch 8/20\n",
            "281/281 [==============================] - 78s 276ms/step - loss: 0.0948 - accuracy: 0.9743 - val_loss: 0.0429 - val_accuracy: 0.9860\n",
            "Epoch 9/20\n",
            "281/281 [==============================] - 78s 278ms/step - loss: 0.0817 - accuracy: 0.9747 - val_loss: 0.0416 - val_accuracy: 0.9860\n",
            "Epoch 10/20\n",
            "281/281 [==============================] - 78s 276ms/step - loss: 0.0793 - accuracy: 0.9740 - val_loss: 0.0389 - val_accuracy: 0.9865\n",
            "Epoch 11/20\n",
            "281/281 [==============================] - 77s 274ms/step - loss: 0.0648 - accuracy: 0.9789 - val_loss: 0.0584 - val_accuracy: 0.9820\n",
            "Epoch 12/20\n",
            "281/281 [==============================] - 77s 275ms/step - loss: 0.0672 - accuracy: 0.9785 - val_loss: 0.0295 - val_accuracy: 0.9885\n",
            "Epoch 13/20\n",
            "281/281 [==============================] - 77s 276ms/step - loss: 0.0732 - accuracy: 0.9775 - val_loss: 0.0369 - val_accuracy: 0.9905\n",
            "Epoch 14/20\n",
            "281/281 [==============================] - 77s 275ms/step - loss: 0.0606 - accuracy: 0.9810 - val_loss: 0.0315 - val_accuracy: 0.9905\n",
            "Epoch 15/20\n",
            "281/281 [==============================] - 77s 275ms/step - loss: 0.0630 - accuracy: 0.9799 - val_loss: 0.0472 - val_accuracy: 0.9865\n",
            "Epoch 16/20\n",
            "281/281 [==============================] - 77s 274ms/step - loss: 0.0675 - accuracy: 0.9807 - val_loss: 0.0331 - val_accuracy: 0.9900\n",
            "Epoch 17/20\n",
            "281/281 [==============================] - 77s 275ms/step - loss: 0.0478 - accuracy: 0.9845 - val_loss: 0.0254 - val_accuracy: 0.9920\n",
            "Epoch 18/20\n",
            "281/281 [==============================] - 77s 273ms/step - loss: 0.0465 - accuracy: 0.9861 - val_loss: 0.0198 - val_accuracy: 0.9945\n",
            "Epoch 19/20\n",
            "281/281 [==============================] - 77s 274ms/step - loss: 0.0403 - accuracy: 0.9878 - val_loss: 0.0251 - val_accuracy: 0.9930\n",
            "Epoch 20/20\n",
            "281/281 [==============================] - 77s 275ms/step - loss: 0.0422 - accuracy: 0.9857 - val_loss: 0.0283 - val_accuracy: 0.9920\n",
            "CNN Model 4: Epochs=20, Training accuracy=0.98740, Validation accuracy=0.99450\n",
            "Individual Net : 5\n",
            "Epoch 1/20\n",
            "281/281 [==============================] - 78s 275ms/step - loss: 1.3132 - accuracy: 0.6032 - val_loss: 4.2416 - val_accuracy: 0.3360\n",
            "Epoch 2/20\n",
            "281/281 [==============================] - 77s 274ms/step - loss: 0.2491 - accuracy: 0.9224 - val_loss: 0.4828 - val_accuracy: 0.8635\n",
            "Epoch 3/20\n",
            "281/281 [==============================] - 77s 274ms/step - loss: 0.1674 - accuracy: 0.9453 - val_loss: 0.0587 - val_accuracy: 0.9815\n",
            "Epoch 4/20\n",
            "281/281 [==============================] - 77s 274ms/step - loss: 0.1218 - accuracy: 0.9632 - val_loss: 0.0680 - val_accuracy: 0.9785\n",
            "Epoch 5/20\n",
            "281/281 [==============================] - 77s 275ms/step - loss: 0.1082 - accuracy: 0.9688 - val_loss: 0.0413 - val_accuracy: 0.9875\n",
            "Epoch 6/20\n",
            "281/281 [==============================] - 78s 276ms/step - loss: 0.1119 - accuracy: 0.9665 - val_loss: 0.0325 - val_accuracy: 0.9905\n",
            "Epoch 7/20\n",
            "281/281 [==============================] - 77s 275ms/step - loss: 0.0885 - accuracy: 0.9737 - val_loss: 0.0417 - val_accuracy: 0.9865\n",
            "Epoch 8/20\n",
            "281/281 [==============================] - 77s 274ms/step - loss: 0.0854 - accuracy: 0.9749 - val_loss: 0.0361 - val_accuracy: 0.9865\n",
            "Epoch 9/20\n",
            "281/281 [==============================] - 77s 276ms/step - loss: 0.0855 - accuracy: 0.9744 - val_loss: 0.0398 - val_accuracy: 0.9890\n",
            "Epoch 10/20\n",
            "281/281 [==============================] - 78s 276ms/step - loss: 0.0662 - accuracy: 0.9809 - val_loss: 0.0317 - val_accuracy: 0.9890\n",
            "Epoch 11/20\n",
            "281/281 [==============================] - 77s 275ms/step - loss: 0.0597 - accuracy: 0.9821 - val_loss: 0.0277 - val_accuracy: 0.9905\n",
            "Epoch 12/20\n",
            "281/281 [==============================] - 77s 276ms/step - loss: 0.0585 - accuracy: 0.9823 - val_loss: 0.0283 - val_accuracy: 0.9915\n",
            "Epoch 13/20\n",
            "281/281 [==============================] - 78s 278ms/step - loss: 0.0539 - accuracy: 0.9839 - val_loss: 0.0250 - val_accuracy: 0.9915\n",
            "Epoch 14/20\n",
            "281/281 [==============================] - 79s 280ms/step - loss: 0.0646 - accuracy: 0.9803 - val_loss: 0.0382 - val_accuracy: 0.9895\n",
            "Epoch 15/20\n",
            "281/281 [==============================] - 79s 280ms/step - loss: 0.0512 - accuracy: 0.9852 - val_loss: 0.0313 - val_accuracy: 0.9890\n",
            "Epoch 16/20\n",
            "281/281 [==============================] - 79s 280ms/step - loss: 0.0488 - accuracy: 0.9852 - val_loss: 0.0263 - val_accuracy: 0.9930\n",
            "Epoch 17/20\n",
            "281/281 [==============================] - 79s 282ms/step - loss: 0.0412 - accuracy: 0.9880 - val_loss: 0.0231 - val_accuracy: 0.9930\n",
            "Epoch 18/20\n",
            "281/281 [==============================] - 78s 277ms/step - loss: 0.0396 - accuracy: 0.9882 - val_loss: 0.0276 - val_accuracy: 0.9925\n",
            "Epoch 19/20\n",
            "281/281 [==============================] - 78s 277ms/step - loss: 0.0413 - accuracy: 0.9872 - val_loss: 0.0214 - val_accuracy: 0.9950\n",
            "Epoch 20/20\n",
            "281/281 [==============================] - 78s 276ms/step - loss: 0.0354 - accuracy: 0.9888 - val_loss: 0.0235 - val_accuracy: 0.9955\n",
            "CNN Model 5: Epochs=20, Training accuracy=0.98827, Validation accuracy=0.99550\n",
            "Individual Net : 6\n",
            "Epoch 1/20\n",
            "281/281 [==============================] - 79s 277ms/step - loss: 1.4138 - accuracy: 0.5842 - val_loss: 6.7760 - val_accuracy: 0.1100\n",
            "Epoch 2/20\n",
            "281/281 [==============================] - 77s 276ms/step - loss: 0.2323 - accuracy: 0.9287 - val_loss: 0.0785 - val_accuracy: 0.9735\n",
            "Epoch 3/20\n",
            "281/281 [==============================] - 77s 275ms/step - loss: 0.1687 - accuracy: 0.9507 - val_loss: 0.0551 - val_accuracy: 0.9840\n",
            "Epoch 4/20\n",
            "281/281 [==============================] - 77s 276ms/step - loss: 0.1376 - accuracy: 0.9573 - val_loss: 0.0356 - val_accuracy: 0.9870\n",
            "Epoch 5/20\n",
            "281/281 [==============================] - 77s 275ms/step - loss: 0.1147 - accuracy: 0.9657 - val_loss: 0.0270 - val_accuracy: 0.9935\n",
            "Epoch 6/20\n",
            "281/281 [==============================] - 78s 276ms/step - loss: 0.0963 - accuracy: 0.9714 - val_loss: 0.0346 - val_accuracy: 0.9885\n",
            "Epoch 7/20\n",
            "281/281 [==============================] - 78s 276ms/step - loss: 0.1009 - accuracy: 0.9705 - val_loss: 0.0387 - val_accuracy: 0.9880\n",
            "Epoch 8/20\n",
            "281/281 [==============================] - 77s 275ms/step - loss: 0.0845 - accuracy: 0.9735 - val_loss: 0.0131 - val_accuracy: 0.9960\n",
            "Epoch 9/20\n",
            "281/281 [==============================] - 78s 276ms/step - loss: 0.0854 - accuracy: 0.9746 - val_loss: 0.0190 - val_accuracy: 0.9935\n",
            "Epoch 10/20\n",
            "281/281 [==============================] - 78s 276ms/step - loss: 0.0812 - accuracy: 0.9768 - val_loss: 0.0197 - val_accuracy: 0.9930\n",
            "Epoch 11/20\n",
            "281/281 [==============================] - 78s 277ms/step - loss: 0.0773 - accuracy: 0.9758 - val_loss: 0.0187 - val_accuracy: 0.9940\n",
            "Epoch 12/20\n",
            "281/281 [==============================] - 78s 276ms/step - loss: 0.0506 - accuracy: 0.9852 - val_loss: 0.0137 - val_accuracy: 0.9960\n",
            "Epoch 13/20\n",
            "281/281 [==============================] - 78s 276ms/step - loss: 0.0444 - accuracy: 0.9857 - val_loss: 0.0108 - val_accuracy: 0.9955\n",
            "Epoch 14/20\n",
            "281/281 [==============================] - 78s 276ms/step - loss: 0.0532 - accuracy: 0.9824 - val_loss: 0.0181 - val_accuracy: 0.9935\n",
            "Epoch 15/20\n",
            "281/281 [==============================] - 77s 276ms/step - loss: 0.0445 - accuracy: 0.9861 - val_loss: 0.0100 - val_accuracy: 0.9975\n",
            "Epoch 16/20\n",
            "281/281 [==============================] - 78s 279ms/step - loss: 0.0410 - accuracy: 0.9881 - val_loss: 0.0115 - val_accuracy: 0.9975\n",
            "Epoch 17/20\n",
            "281/281 [==============================] - 79s 279ms/step - loss: 0.0404 - accuracy: 0.9864 - val_loss: 0.0136 - val_accuracy: 0.9965\n",
            "Epoch 18/20\n",
            "281/281 [==============================] - 78s 277ms/step - loss: 0.0388 - accuracy: 0.9883 - val_loss: 0.0128 - val_accuracy: 0.9970\n",
            "Epoch 19/20\n",
            "281/281 [==============================] - 78s 277ms/step - loss: 0.0344 - accuracy: 0.9885 - val_loss: 0.0093 - val_accuracy: 0.9980\n",
            "Epoch 20/20\n",
            "281/281 [==============================] - 78s 277ms/step - loss: 0.0334 - accuracy: 0.9894 - val_loss: 0.0102 - val_accuracy: 0.9975\n",
            "CNN Model 6: Epochs=20, Training accuracy=0.98902, Validation accuracy=0.99800\n",
            "Individual Net : 7\n",
            "Epoch 1/20\n",
            "281/281 [==============================] - 79s 277ms/step - loss: 1.3972 - accuracy: 0.5715 - val_loss: 4.8938 - val_accuracy: 0.2420\n",
            "Epoch 2/20\n",
            "281/281 [==============================] - 78s 278ms/step - loss: 0.2617 - accuracy: 0.9184 - val_loss: 0.2262 - val_accuracy: 0.9245\n",
            "Epoch 3/20\n",
            "281/281 [==============================] - 78s 278ms/step - loss: 0.1828 - accuracy: 0.9471 - val_loss: 0.0800 - val_accuracy: 0.9770\n",
            "Epoch 4/20\n",
            "281/281 [==============================] - 78s 277ms/step - loss: 0.1475 - accuracy: 0.9540 - val_loss: 0.0525 - val_accuracy: 0.9830\n",
            "Epoch 5/20\n",
            "281/281 [==============================] - 78s 277ms/step - loss: 0.1207 - accuracy: 0.9646 - val_loss: 0.1239 - val_accuracy: 0.9625\n",
            "Epoch 6/20\n",
            "281/281 [==============================] - 78s 279ms/step - loss: 0.1058 - accuracy: 0.9667 - val_loss: 0.0315 - val_accuracy: 0.9895\n",
            "Epoch 7/20\n",
            "281/281 [==============================] - 78s 277ms/step - loss: 0.0887 - accuracy: 0.9728 - val_loss: 0.0301 - val_accuracy: 0.9885\n",
            "Epoch 8/20\n",
            "281/281 [==============================] - 78s 277ms/step - loss: 0.0864 - accuracy: 0.9746 - val_loss: 0.0759 - val_accuracy: 0.9755\n",
            "Epoch 9/20\n",
            "281/281 [==============================] - 78s 277ms/step - loss: 0.0906 - accuracy: 0.9733 - val_loss: 0.0224 - val_accuracy: 0.9925\n",
            "Epoch 10/20\n",
            "281/281 [==============================] - 78s 277ms/step - loss: 0.0690 - accuracy: 0.9780 - val_loss: 0.0266 - val_accuracy: 0.9930\n",
            "Epoch 11/20\n",
            "281/281 [==============================] - 78s 278ms/step - loss: 0.0686 - accuracy: 0.9792 - val_loss: 0.0332 - val_accuracy: 0.9905\n",
            "Epoch 12/20\n",
            "281/281 [==============================] - 78s 278ms/step - loss: 0.0750 - accuracy: 0.9761 - val_loss: 0.0355 - val_accuracy: 0.9880\n",
            "Epoch 13/20\n",
            "281/281 [==============================] - 78s 278ms/step - loss: 0.0691 - accuracy: 0.9771 - val_loss: 0.0268 - val_accuracy: 0.9910\n",
            "Epoch 14/20\n",
            "281/281 [==============================] - 78s 277ms/step - loss: 0.0629 - accuracy: 0.9796 - val_loss: 0.0244 - val_accuracy: 0.9920\n",
            "Epoch 15/20\n",
            "281/281 [==============================] - 78s 277ms/step - loss: 0.0484 - accuracy: 0.9849 - val_loss: 0.0280 - val_accuracy: 0.9910\n",
            "Epoch 16/20\n",
            "281/281 [==============================] - 78s 278ms/step - loss: 0.0453 - accuracy: 0.9872 - val_loss: 0.0287 - val_accuracy: 0.9920\n",
            "Epoch 17/20\n",
            "281/281 [==============================] - 78s 278ms/step - loss: 0.0380 - accuracy: 0.9876 - val_loss: 0.0209 - val_accuracy: 0.9940\n",
            "Epoch 18/20\n",
            "281/281 [==============================] - 78s 278ms/step - loss: 0.0417 - accuracy: 0.9883 - val_loss: 0.0237 - val_accuracy: 0.9925\n",
            "Epoch 19/20\n",
            "281/281 [==============================] - 78s 278ms/step - loss: 0.0357 - accuracy: 0.9899 - val_loss: 0.0188 - val_accuracy: 0.9935\n",
            "Epoch 20/20\n",
            "281/281 [==============================] - 78s 277ms/step - loss: 0.0368 - accuracy: 0.9888 - val_loss: 0.0253 - val_accuracy: 0.9900\n",
            "CNN Model 7: Epochs=20, Training accuracy=0.99041, Validation accuracy=0.99400\n",
            "Individual Net : 8\n",
            "Epoch 1/20\n",
            "281/281 [==============================] - 79s 277ms/step - loss: 1.4338 - accuracy: 0.5669 - val_loss: 1.8471 - val_accuracy: 0.4755\n",
            "Epoch 2/20\n",
            "281/281 [==============================] - 78s 279ms/step - loss: 0.2510 - accuracy: 0.9220 - val_loss: 0.0687 - val_accuracy: 0.9780\n",
            "Epoch 3/20\n",
            "281/281 [==============================] - 79s 280ms/step - loss: 0.1710 - accuracy: 0.9478 - val_loss: 0.0499 - val_accuracy: 0.9845\n",
            "Epoch 4/20\n",
            "281/281 [==============================] - 78s 278ms/step - loss: 0.1409 - accuracy: 0.9575 - val_loss: 0.0428 - val_accuracy: 0.9885\n",
            "Epoch 5/20\n",
            "281/281 [==============================] - 78s 277ms/step - loss: 0.1104 - accuracy: 0.9672 - val_loss: 0.0473 - val_accuracy: 0.9835\n",
            "Epoch 6/20\n",
            "281/281 [==============================] - 78s 279ms/step - loss: 0.0951 - accuracy: 0.9707 - val_loss: 0.0538 - val_accuracy: 0.9815\n",
            "Epoch 7/20\n",
            "281/281 [==============================] - 78s 278ms/step - loss: 0.0971 - accuracy: 0.9726 - val_loss: 0.0376 - val_accuracy: 0.9880\n",
            "Epoch 8/20\n",
            "281/281 [==============================] - 78s 277ms/step - loss: 0.0743 - accuracy: 0.9779 - val_loss: 0.0200 - val_accuracy: 0.9940\n",
            "Epoch 9/20\n",
            "281/281 [==============================] - 78s 278ms/step - loss: 0.0617 - accuracy: 0.9811 - val_loss: 0.0327 - val_accuracy: 0.9900\n",
            "Epoch 10/20\n",
            "281/281 [==============================] - 78s 278ms/step - loss: 0.0556 - accuracy: 0.9824 - val_loss: 0.0201 - val_accuracy: 0.9930\n",
            "Epoch 11/20\n",
            "281/281 [==============================] - 77s 275ms/step - loss: 0.0580 - accuracy: 0.9833 - val_loss: 0.0225 - val_accuracy: 0.9930\n",
            "Epoch 12/20\n",
            "281/281 [==============================] - 78s 276ms/step - loss: 0.0541 - accuracy: 0.9838 - val_loss: 0.0171 - val_accuracy: 0.9935\n",
            "Epoch 13/20\n",
            "281/281 [==============================] - 78s 278ms/step - loss: 0.0503 - accuracy: 0.9860 - val_loss: 0.0179 - val_accuracy: 0.9935\n",
            "Epoch 14/20\n",
            "281/281 [==============================] - 78s 277ms/step - loss: 0.0482 - accuracy: 0.9861 - val_loss: 0.0200 - val_accuracy: 0.9920\n",
            "Epoch 15/20\n",
            "281/281 [==============================] - 78s 279ms/step - loss: 0.0371 - accuracy: 0.9880 - val_loss: 0.0178 - val_accuracy: 0.9945\n",
            "Epoch 16/20\n",
            "281/281 [==============================] - 78s 279ms/step - loss: 0.0376 - accuracy: 0.9889 - val_loss: 0.0184 - val_accuracy: 0.9930\n",
            "Epoch 17/20\n",
            "281/281 [==============================] - 78s 278ms/step - loss: 0.0395 - accuracy: 0.9883 - val_loss: 0.0173 - val_accuracy: 0.9955\n",
            "Epoch 18/20\n",
            "281/281 [==============================] - 78s 279ms/step - loss: 0.0408 - accuracy: 0.9871 - val_loss: 0.0177 - val_accuracy: 0.9940\n",
            "Epoch 19/20\n",
            "281/281 [==============================] - 78s 279ms/step - loss: 0.0371 - accuracy: 0.9891 - val_loss: 0.0202 - val_accuracy: 0.9940\n",
            "Epoch 20/20\n",
            "281/281 [==============================] - 78s 279ms/step - loss: 0.0435 - accuracy: 0.9867 - val_loss: 0.0176 - val_accuracy: 0.9945\n",
            "CNN Model 8: Epochs=20, Training accuracy=0.98890, Validation accuracy=0.99550\n",
            "Individual Net : 9\n",
            "Epoch 1/20\n",
            "281/281 [==============================] - 79s 278ms/step - loss: 1.3764 - accuracy: 0.5868 - val_loss: 3.5986 - val_accuracy: 0.3425\n",
            "Epoch 2/20\n",
            "281/281 [==============================] - 78s 279ms/step - loss: 0.2548 - accuracy: 0.9178 - val_loss: 0.1094 - val_accuracy: 0.9660\n",
            "Epoch 3/20\n",
            "281/281 [==============================] - 78s 278ms/step - loss: 0.1776 - accuracy: 0.9439 - val_loss: 0.0643 - val_accuracy: 0.9815\n",
            "Epoch 4/20\n",
            "281/281 [==============================] - 78s 278ms/step - loss: 0.1350 - accuracy: 0.9595 - val_loss: 0.0521 - val_accuracy: 0.9830\n",
            "Epoch 5/20\n",
            "281/281 [==============================] - 78s 278ms/step - loss: 0.1185 - accuracy: 0.9650 - val_loss: 0.0395 - val_accuracy: 0.9870\n",
            "Epoch 6/20\n",
            "281/281 [==============================] - 78s 279ms/step - loss: 0.1143 - accuracy: 0.9631 - val_loss: 0.0389 - val_accuracy: 0.9845\n",
            "Epoch 7/20\n",
            "281/281 [==============================] - 78s 279ms/step - loss: 0.0965 - accuracy: 0.9726 - val_loss: 0.0380 - val_accuracy: 0.9860\n",
            "Epoch 8/20\n",
            "281/281 [==============================] - 78s 278ms/step - loss: 0.0914 - accuracy: 0.9733 - val_loss: 0.0458 - val_accuracy: 0.9855\n",
            "Epoch 9/20\n",
            "281/281 [==============================] - 78s 278ms/step - loss: 0.0707 - accuracy: 0.9777 - val_loss: 0.0334 - val_accuracy: 0.9890\n",
            "Epoch 10/20\n",
            "281/281 [==============================] - 79s 281ms/step - loss: 0.0574 - accuracy: 0.9821 - val_loss: 0.0239 - val_accuracy: 0.9915\n",
            "Epoch 11/20\n",
            "281/281 [==============================] - 78s 279ms/step - loss: 0.0648 - accuracy: 0.9798 - val_loss: 0.0207 - val_accuracy: 0.9940\n",
            "Epoch 12/20\n",
            "281/281 [==============================] - 78s 278ms/step - loss: 0.0571 - accuracy: 0.9830 - val_loss: 0.0269 - val_accuracy: 0.9920\n",
            "Epoch 13/20\n",
            "281/281 [==============================] - 78s 279ms/step - loss: 0.0591 - accuracy: 0.9817 - val_loss: 0.0241 - val_accuracy: 0.9920\n",
            "Epoch 14/20\n",
            "281/281 [==============================] - 79s 279ms/step - loss: 0.0569 - accuracy: 0.9834 - val_loss: 0.0205 - val_accuracy: 0.9925\n",
            "Epoch 15/20\n",
            "281/281 [==============================] - 79s 280ms/step - loss: 0.0484 - accuracy: 0.9850 - val_loss: 0.0196 - val_accuracy: 0.9930\n",
            "Epoch 16/20\n",
            "281/281 [==============================] - 79s 280ms/step - loss: 0.0436 - accuracy: 0.9872 - val_loss: 0.0195 - val_accuracy: 0.9940\n",
            "Epoch 17/20\n",
            "281/281 [==============================] - 79s 280ms/step - loss: 0.0452 - accuracy: 0.9859 - val_loss: 0.0175 - val_accuracy: 0.9935\n",
            "Epoch 18/20\n",
            "281/281 [==============================] - 79s 279ms/step - loss: 0.0423 - accuracy: 0.9870 - val_loss: 0.0147 - val_accuracy: 0.9955\n",
            "Epoch 19/20\n",
            "281/281 [==============================] - 78s 279ms/step - loss: 0.0316 - accuracy: 0.9897 - val_loss: 0.0167 - val_accuracy: 0.9945\n",
            "Epoch 20/20\n",
            "281/281 [==============================] - 78s 278ms/step - loss: 0.0359 - accuracy: 0.9883 - val_loss: 0.0169 - val_accuracy: 0.9935\n",
            "CNN Model 9: Epochs=20, Training accuracy=0.98890, Validation accuracy=0.99550\n",
            "Individual Net : 10\n",
            "Epoch 1/20\n",
            "281/281 [==============================] - 79s 278ms/step - loss: 1.3731 - accuracy: 0.5871 - val_loss: 2.1934 - val_accuracy: 0.3985\n",
            "Epoch 2/20\n",
            "281/281 [==============================] - 78s 278ms/step - loss: 0.2427 - accuracy: 0.9222 - val_loss: 0.1812 - val_accuracy: 0.9390\n",
            "Epoch 3/20\n",
            "281/281 [==============================] - 78s 279ms/step - loss: 0.1577 - accuracy: 0.9507 - val_loss: 0.0641 - val_accuracy: 0.9800\n",
            "Epoch 4/20\n",
            "281/281 [==============================] - 79s 280ms/step - loss: 0.1343 - accuracy: 0.9593 - val_loss: 0.0529 - val_accuracy: 0.9880\n",
            "Epoch 5/20\n",
            "281/281 [==============================] - 79s 280ms/step - loss: 0.1123 - accuracy: 0.9667 - val_loss: 0.0480 - val_accuracy: 0.9875\n",
            "Epoch 6/20\n",
            "281/281 [==============================] - 79s 281ms/step - loss: 0.1003 - accuracy: 0.9677 - val_loss: 0.0528 - val_accuracy: 0.9855\n",
            "Epoch 7/20\n",
            "281/281 [==============================] - 79s 279ms/step - loss: 0.0999 - accuracy: 0.9704 - val_loss: 0.0544 - val_accuracy: 0.9865\n",
            "Epoch 8/20\n",
            "281/281 [==============================] - 78s 279ms/step - loss: 0.0693 - accuracy: 0.9767 - val_loss: 0.0440 - val_accuracy: 0.9880\n",
            "Epoch 9/20\n",
            "281/281 [==============================] - 79s 283ms/step - loss: 0.0693 - accuracy: 0.9796 - val_loss: 0.0359 - val_accuracy: 0.9915\n",
            "Epoch 10/20\n",
            "281/281 [==============================] - 79s 282ms/step - loss: 0.0558 - accuracy: 0.9828 - val_loss: 0.0449 - val_accuracy: 0.9885\n",
            "Epoch 11/20\n",
            "281/281 [==============================] - 79s 280ms/step - loss: 0.0591 - accuracy: 0.9820 - val_loss: 0.0284 - val_accuracy: 0.9915\n",
            "Epoch 12/20\n",
            "281/281 [==============================] - 79s 279ms/step - loss: 0.0572 - accuracy: 0.9837 - val_loss: 0.0405 - val_accuracy: 0.9890\n",
            "Epoch 13/20\n",
            "281/281 [==============================] - 79s 279ms/step - loss: 0.0444 - accuracy: 0.9863 - val_loss: 0.0286 - val_accuracy: 0.9925\n",
            "Epoch 14/20\n",
            "281/281 [==============================] - 78s 279ms/step - loss: 0.0439 - accuracy: 0.9858 - val_loss: 0.0322 - val_accuracy: 0.9920\n",
            "Epoch 15/20\n",
            "281/281 [==============================] - 79s 279ms/step - loss: 0.0402 - accuracy: 0.9874 - val_loss: 0.0312 - val_accuracy: 0.9920\n",
            "Epoch 16/20\n",
            "281/281 [==============================] - 78s 278ms/step - loss: 0.0439 - accuracy: 0.9863 - val_loss: 0.0279 - val_accuracy: 0.9930\n",
            "Epoch 17/20\n",
            "281/281 [==============================] - 78s 276ms/step - loss: 0.0392 - accuracy: 0.9878 - val_loss: 0.0265 - val_accuracy: 0.9940\n",
            "Epoch 18/20\n",
            "281/281 [==============================] - 78s 278ms/step - loss: 0.0437 - accuracy: 0.9873 - val_loss: 0.0361 - val_accuracy: 0.9900\n",
            "Epoch 19/20\n",
            "281/281 [==============================] - 78s 278ms/step - loss: 0.0444 - accuracy: 0.9865 - val_loss: 0.0299 - val_accuracy: 0.9905\n",
            "Epoch 20/20\n",
            "281/281 [==============================] - 78s 279ms/step - loss: 0.0349 - accuracy: 0.9884 - val_loss: 0.0301 - val_accuracy: 0.9920\n",
            "CNN Model 10: Epochs=20, Training accuracy=0.98857, Validation accuracy=0.99400\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XY8eDDpP-M5X"
      },
      "source": [
        "#Result\n",
        "results = np.zeros( (test.shape[0],10) ) \n",
        "for j in range(nets):\n",
        "    results = results + model[j].predict(test)\n",
        " \n",
        "results = np.argmax(results,axis = 1)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "id": "W-cgYjqQ-O4-",
        "outputId": "035ea708-4772-468f-e26e-2e2561e6680e"
      },
      "source": [
        "#Test on result\n",
        "plt.imshow(test[0][:,:,0])\n",
        "plt.title(results[0])"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, '2')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 679
        },
        "id": "sExuVuOa-RP8",
        "outputId": "f2b3710c-97cb-47b1-ded1-f4c32e698c03"
      },
      "source": [
        "L = 4\n",
        "W = 4\n",
        "fig, axes = plt.subplots(L, W, figsize = (12,12))\n",
        "axes = axes.ravel()\n",
        "\n",
        "for i in np.arange(0, L * W):  \n",
        "    axes[i].imshow(test[i].reshape(28,28))\n",
        "    axes[i].set_title(results[i])\n",
        "    axes[i].axis('off')\n",
        "plt.subplots_adjust(wspace=0.5)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x864 with 16 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}